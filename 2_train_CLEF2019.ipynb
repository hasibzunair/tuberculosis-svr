{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the 3D CNN on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2507,
     "status": "ok",
     "timestamp": 1580190695724,
     "user": {
      "displayName": "Md Hasib Zunair 1320262643",
      "photoUrl": "",
      "userId": "12069756592370329757"
     },
     "user_tz": 300
    },
    "id": "tSs8XjcdteBW",
    "outputId": "ddf4bcee-cf2f-4633-b8a2-7293d5f1969f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.3.1\n",
      "Tensorflow Version 2.0.0\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# Print version\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"Tensorflow Version\", tf.__version__)\n",
    "\n",
    "# Helpers functions\n",
    "\n",
    "def create_directory(directory):\n",
    "    '''\n",
    "    Creates a new folder in the specified directory if the folder doesn't exist.\n",
    "    INPUT\n",
    "        directory: Folder to be created, called as \"folder/\".\n",
    "    OUTPUT\n",
    "        New folder in the current directory.\n",
    "    '''\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "# Define paths\n",
    "base_path = os.path.abspath(\"./\") # Your root directory\n",
    "dataset_path = os.path.join(base_path, \"dataset\") # Your dataset folder\n",
    "model_path = os.path.join(base_path, \"models\")\n",
    "log_path = os.path.join(base_path, \"logs\")\n",
    "\n",
    "# Name your experiment\n",
    "experiment_name = \"siz\"\n",
    "\n",
    "create_directory(log_path)\n",
    "create_directory(log_path+\"/\"+experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4346,
     "status": "ok",
     "timestamp": 1580190697582,
     "user": {
      "displayName": "Md Hasib Zunair 1320262643",
      "photoUrl": "",
      "userId": "12069756592370329757"
     },
     "user_tz": 300
    },
    "id": "G4VLrAcoiKmV",
    "outputId": "3a24fbda-5486-446a-d494-b628c72ac965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 128, 128, 64) (218, 2)\n",
      "(174, 128, 128, 64) (174, 2) (44, 128, 128, 64) (44, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "raw = np.load('{}/x_train_sss.npy'.format(dataset_path))\n",
    "labels = np.load('{}/y_train_clef.npy'.format(dataset_path))\n",
    "\n",
    "print(raw.shape, labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw, labels, test_size=0.2, random_state=1)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# If not cross validation, do this 60 20 20 split\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "#print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4329,
     "status": "ok",
     "timestamp": 1580190697588,
     "user": {
      "displayName": "Md Hasib Zunair 1320262643",
      "photoUrl": "",
      "userId": "12069756592370329757"
     },
     "user_tz": 300
    },
    "id": "A72uxzbRtpsd",
    "outputId": "b352febb-de36-4da1-9126-fa0e0cfbd5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 87\n",
      "(174, 128, 128, 64, 1) (44, 128, 128, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "y = np.array([np.argmax(x) for x in y_train])\n",
    "print(np.count_nonzero(y == 1), np.count_nonzero(y == 0))\n",
    "\n",
    "# For 60 20 20 split\n",
    "# train 65, 65\n",
    "# val 22, 22\n",
    "# test 20, 24\n",
    "\n",
    "\n",
    "def expand_dims(val):\n",
    "    val_exp = np.expand_dims(val, axis=4)\n",
    "    return val_exp\n",
    "\n",
    "X_train = expand_dims(X_train)\n",
    "#X_val = expand_dims(X_val)\n",
    "X_test = expand_dims(X_test)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4827,
     "status": "ok",
     "timestamp": 1580190698104,
     "user": {
      "displayName": "Md Hasib Zunair 1320262643",
      "photoUrl": "",
      "userId": "12069756592370329757"
     },
     "user_tz": 300
    },
    "id": "R-O8vQnPtp4s",
    "outputId": "331c3a78-0f03-4bbc-e8e1-73a1dec79497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [1. 1.]\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 64, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 126, 126, 62, 64)  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 63, 63, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 63, 63, 31, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 61, 61, 29, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 30, 30, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 28, 28, 12, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 14, 14, 6, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 6, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 12, 12, 4, 256)    884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 6, 6, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 10,659,522\n",
      "Trainable params: 10,658,498\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "weights_path = \"{}/{}.h5\".format(log_path+\"/\"+experiment_name, \"best_model\")\n",
    "checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, monitor='val_loss', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-8, mode='auto') # new_lr = lr * factor\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, verbose=1, patience=8, mode='auto', restore_best_weights=True)\n",
    "csv_logger = CSVLogger('{}/training.csv'.format(log_path+\"/\"+experiment_name))\n",
    "\n",
    "# Define class weights for imbalacned data\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(np.argmax(y_train, axis=1)), np.argmax(y_train, axis=1))\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "\n",
    "def awesome_3D_network():\n",
    "    \n",
    "    filter_size = 32\n",
    "    depth = 64\n",
    "    input_layer = Input((128, 128, depth, 1)) # 1 is just dummy dimension good for nothing \n",
    "    \n",
    "    conv_layer1 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(input_layer)\n",
    "    pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer1)\n",
    "\n",
    "    pooling_layer1 = BatchNormalization()(pooling_layer1)  \n",
    "    conv_layer2 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(pooling_layer1)\n",
    "    pooling_layer2 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer2)\n",
    "    pooling_layer2 = BatchNormalization()(pooling_layer2)\n",
    "    conv_layer3 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(pooling_layer1)\n",
    "    pooling_layer3 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer3)\n",
    "    pooling_layer3 = BatchNormalization()(pooling_layer3)\n",
    "    conv_layer4 = Conv3D(filters=128, kernel_size=(3, 3, 3), activation='relu')(pooling_layer3)\n",
    "    pooling_layer4 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer4)\n",
    "    pooling_layer4 = BatchNormalization()(pooling_layer4)\n",
    "    conv_layer5 = Conv3D(filters=256, kernel_size=(3, 3, 3), activation='relu')(pooling_layer4)\n",
    "    pooling_layer5 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer5)\n",
    "    \n",
    "    pooling_layer9 = BatchNormalization()(pooling_layer5)\n",
    "    flatten_layer = Flatten()(pooling_layer9)\n",
    "\n",
    "    #dense_layer1 = Dense(units=1028, activation='relu')(flatten_layer)\n",
    "    #dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    \n",
    "    #dense_layer2 = Dense(units=1028, activation='relu')(flatten_layer)\n",
    "    #dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    \n",
    "    dense_layer3 = Dense(units=512, activation='relu')(flatten_layer)\n",
    "    dense_layer3 = Dropout(0.4)(dense_layer3)\n",
    "\n",
    "    dense_layer4 = Dense(units=256, activation='relu')(dense_layer3)\n",
    "    dense_layer4 = Dropout(0.4)(dense_layer3)\n",
    "  \n",
    "    output_layer = Dense(units=2, activation='softmax')(dense_layer4)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(loss='mae', optimizer=SGD(lr=1e-06, momentum=0.99, decay=0.0, nesterov=False), metrics=['acc']) \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = None\n",
    "model = awesome_3D_network()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bI2F2Zw5-e2D",
    "outputId": "678ae6ec-c3db-4e85-f01c-2fcfcfa8c05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
      "(174, 128, 128, 64, 1) (174,)\n",
      "Fold - 0 (139, 128, 128, 64, 1) (139,) (35, 128, 128, 64, 1) (35,)\n",
      "Train on 139 samples, validate on 35 samples\n",
      "Epoch 1/100\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 0.4622 - acc: 0.5827 - val_loss: 0.5017 - val_acc: 0.4857\n",
      "Epoch 2/100\n",
      "139/139 [==============================] - 6s 40ms/step - loss: 0.4291 - acc: 0.5899 - val_loss: 0.5062 - val_acc: 0.4857\n",
      "Epoch 3/100\n",
      "139/139 [==============================] - 6s 41ms/step - loss: 0.4223 - acc: 0.5971 - val_loss: 0.5097 - val_acc: 0.4857\n",
      "Epoch 4/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.4337 - acc: 0.5755 - val_loss: 0.5118 - val_acc: 0.4857\n",
      "Epoch 5/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.3784 - acc: 0.6475 - val_loss: 0.5129 - val_acc: 0.4857\n",
      "Epoch 6/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.3773 - acc: 0.6403 - val_loss: 0.5134 - val_acc: 0.4857\n",
      "Epoch 7/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.3755 - acc: 0.6259 - val_loss: 0.5140 - val_acc: 0.4857\n",
      "Epoch 8/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.3290 - acc: 0.7122 - val_loss: 0.5135 - val_acc: 0.4857\n",
      "Epoch 9/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.2882 - acc: 0.7482 - val_loss: 0.5124 - val_acc: 0.4857\n",
      "Epoch 10/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.3430 - acc: 0.6763 - val_loss: 0.4829 - val_acc: 0.5143\n",
      "Epoch 11/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.2882 - acc: 0.7194 - val_loss: 0.5044 - val_acc: 0.4286\n",
      "Epoch 12/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.2687 - acc: 0.7482 - val_loss: 0.4934 - val_acc: 0.4571\n",
      "Epoch 13/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.2452 - acc: 0.7698 - val_loss: 0.4847 - val_acc: 0.4857\n",
      "Epoch 14/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.2337 - acc: 0.7986 - val_loss: 0.4864 - val_acc: 0.5429\n",
      "Epoch 15/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.2240 - acc: 0.8129 - val_loss: 0.4503 - val_acc: 0.5714\n",
      "Epoch 16/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1925 - acc: 0.8273 - val_loss: 0.4419 - val_acc: 0.5429\n",
      "Epoch 17/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1809 - acc: 0.8705 - val_loss: 0.4338 - val_acc: 0.5429\n",
      "Epoch 18/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1917 - acc: 0.8345 - val_loss: 0.4341 - val_acc: 0.6000\n",
      "Epoch 19/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1792 - acc: 0.8345 - val_loss: 0.4421 - val_acc: 0.5714\n",
      "Epoch 20/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1489 - acc: 0.8849 - val_loss: 0.4428 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1328 - acc: 0.9209 - val_loss: 0.4189 - val_acc: 0.6571\n",
      "Epoch 22/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1210 - acc: 0.9137 - val_loss: 0.3987 - val_acc: 0.7143\n",
      "Epoch 23/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1202 - acc: 0.9209 - val_loss: 0.4265 - val_acc: 0.6286\n",
      "Epoch 24/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0994 - acc: 0.9568 - val_loss: 0.4311 - val_acc: 0.5429\n",
      "Epoch 25/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.1066 - acc: 0.9209 - val_loss: 0.4173 - val_acc: 0.6571\n",
      "Epoch 26/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0915 - acc: 0.9496 - val_loss: 0.4424 - val_acc: 0.5429\n",
      "Epoch 27/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0736 - acc: 0.9640 - val_loss: 0.4239 - val_acc: 0.6000\n",
      "Epoch 28/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0877 - acc: 0.9353 - val_loss: 0.4088 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0802 - acc: 0.9568 - val_loss: 0.4046 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0628 - acc: 0.9712 - val_loss: 0.4151 - val_acc: 0.6286\n",
      "Epoch 31/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0628 - acc: 0.9712 - val_loss: 0.4185 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0652 - acc: 0.9712 - val_loss: 0.4061 - val_acc: 0.6286\n",
      "Epoch 33/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0439 - acc: 0.9856 - val_loss: 0.4140 - val_acc: 0.6000\n",
      "Epoch 34/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0582 - acc: 0.9712 - val_loss: 0.4183 - val_acc: 0.6286\n",
      "Epoch 35/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0432 - acc: 0.9928 - val_loss: 0.4211 - val_acc: 0.6571\n",
      "Epoch 36/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0448 - acc: 0.9856 - val_loss: 0.4075 - val_acc: 0.6571\n",
      "Epoch 37/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0292 - acc: 0.9928 - val_loss: 0.3962 - val_acc: 0.6286\n",
      "Epoch 38/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0463 - acc: 0.9784 - val_loss: 0.4035 - val_acc: 0.6571\n",
      "Epoch 39/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.3998 - val_acc: 0.6571\n",
      "Epoch 40/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0498 - acc: 0.9784 - val_loss: 0.4050 - val_acc: 0.6286\n",
      "Epoch 41/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0329 - acc: 1.0000 - val_loss: 0.4187 - val_acc: 0.6000\n",
      "Epoch 42/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0425 - acc: 0.9784 - val_loss: 0.4291 - val_acc: 0.6286\n",
      "Epoch 43/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0391 - acc: 0.9856 - val_loss: 0.4312 - val_acc: 0.6286\n",
      "Epoch 44/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0316 - acc: 0.9928 - val_loss: 0.4226 - val_acc: 0.6857\n",
      "Epoch 45/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0419 - acc: 0.9856 - val_loss: 0.3966 - val_acc: 0.6857\n",
      "Epoch 46/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0336 - acc: 0.9856 - val_loss: 0.3870 - val_acc: 0.6571\n",
      "Epoch 47/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.3889 - val_acc: 0.7143\n",
      "Epoch 48/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.3863 - val_acc: 0.6857\n",
      "Epoch 49/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.3963 - val_acc: 0.6857\n",
      "Epoch 50/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.3986 - val_acc: 0.6857\n",
      "Epoch 51/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0322 - acc: 1.0000 - val_loss: 0.3942 - val_acc: 0.6286\n",
      "Epoch 52/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.3984 - val_acc: 0.6286\n",
      "Epoch 53/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0268 - acc: 0.9856 - val_loss: 0.4063 - val_acc: 0.5714\n",
      "Epoch 54/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0242 - acc: 0.9928 - val_loss: 0.4185 - val_acc: 0.6286\n",
      "Epoch 55/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.4181 - val_acc: 0.6571\n",
      "Epoch 56/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0319 - acc: 0.9928 - val_loss: 0.4118 - val_acc: 0.6286\n",
      "Epoch 57/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.3932 - val_acc: 0.6286\n",
      "Epoch 58/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0328 - acc: 0.9856 - val_loss: 0.4048 - val_acc: 0.6571\n",
      "Epoch 59/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0215 - acc: 0.9928 - val_loss: 0.4085 - val_acc: 0.6571\n",
      "Epoch 60/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.4071 - val_acc: 0.6286\n",
      "Epoch 61/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0224 - acc: 0.9928 - val_loss: 0.3976 - val_acc: 0.6286\n",
      "Epoch 62/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.3921 - val_acc: 0.6571\n",
      "Epoch 63/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.4026 - val_acc: 0.6571\n",
      "Epoch 64/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.4131 - val_acc: 0.6286\n",
      "Epoch 65/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.4134 - val_acc: 0.6571\n",
      "Epoch 66/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0246 - acc: 0.9928 - val_loss: 0.4087 - val_acc: 0.6571\n",
      "Epoch 67/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4058 - val_acc: 0.6571\n",
      "Epoch 68/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0183 - acc: 0.9928 - val_loss: 0.4001 - val_acc: 0.6571\n",
      "Epoch 69/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0172 - acc: 0.9928 - val_loss: 0.4007 - val_acc: 0.6286\n",
      "Epoch 70/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4031 - val_acc: 0.6000\n",
      "Epoch 71/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0205 - acc: 0.9928 - val_loss: 0.4117 - val_acc: 0.5714\n",
      "Epoch 72/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4095 - val_acc: 0.6286\n",
      "Epoch 73/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.4056 - val_acc: 0.6571\n",
      "Epoch 74/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0134 - acc: 0.9928 - val_loss: 0.4091 - val_acc: 0.6000\n",
      "Epoch 75/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.4115 - val_acc: 0.6571\n",
      "Epoch 76/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4026 - val_acc: 0.6571\n",
      "Epoch 77/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3972 - val_acc: 0.6571\n",
      "Epoch 78/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0178 - acc: 0.9928 - val_loss: 0.3978 - val_acc: 0.6286\n",
      "Epoch 79/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4015 - val_acc: 0.6571\n",
      "Epoch 80/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3972 - val_acc: 0.6571\n",
      "Epoch 81/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3933 - val_acc: 0.6571\n",
      "Epoch 82/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3927 - val_acc: 0.6857\n",
      "Epoch 83/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3973 - val_acc: 0.6857\n",
      "Epoch 84/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3974 - val_acc: 0.6857\n",
      "Epoch 85/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3962 - val_acc: 0.6286\n",
      "Epoch 86/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3967 - val_acc: 0.6571\n",
      "Epoch 87/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3942 - val_acc: 0.6571\n",
      "Epoch 88/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3993 - val_acc: 0.6857\n",
      "Epoch 89/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4066 - val_acc: 0.6857\n",
      "Epoch 90/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4097 - val_acc: 0.6571\n",
      "Epoch 91/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4140 - val_acc: 0.6286\n",
      "Epoch 92/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0125 - acc: 0.9928 - val_loss: 0.4093 - val_acc: 0.6571\n",
      "Epoch 93/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4022 - val_acc: 0.6571\n",
      "Epoch 94/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3913 - val_acc: 0.6857\n",
      "Epoch 95/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3898 - val_acc: 0.7143\n",
      "Epoch 96/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3938 - val_acc: 0.6857\n",
      "Epoch 97/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3954 - val_acc: 0.6571\n",
      "Epoch 98/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3926 - val_acc: 0.6571\n",
      "Epoch 99/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3889 - val_acc: 0.6857\n",
      "Epoch 100/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3871 - val_acc: 0.6571\n",
      "Fold 0 accuracy : 65.71428571428571\n",
      "Fold - 1 (139, 128, 128, 64, 1) (139,) (35, 128, 128, 64, 1) (35,)\n",
      "Train on 139 samples, validate on 35 samples\n",
      "Epoch 1/100\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 0.5646 - acc: 0.4245 - val_loss: 0.4958 - val_acc: 0.5143\n",
      "Epoch 2/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.5040 - acc: 0.4820 - val_loss: 0.4935 - val_acc: 0.5143\n",
      "Epoch 3/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4598 - acc: 0.5324 - val_loss: 0.4936 - val_acc: 0.5143\n",
      "Epoch 4/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4998 - acc: 0.4892 - val_loss: 0.4948 - val_acc: 0.5143\n",
      "Epoch 5/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4204 - acc: 0.5899 - val_loss: 0.4961 - val_acc: 0.5143\n",
      "Epoch 6/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4399 - acc: 0.5755 - val_loss: 0.5016 - val_acc: 0.5143\n",
      "Epoch 7/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4435 - acc: 0.5540 - val_loss: 0.4982 - val_acc: 0.5429\n",
      "Epoch 8/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3622 - acc: 0.6403 - val_loss: 0.5078 - val_acc: 0.4857\n",
      "Epoch 9/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3793 - acc: 0.6403 - val_loss: 0.5004 - val_acc: 0.5714\n",
      "Epoch 10/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3507 - acc: 0.6547 - val_loss: 0.4941 - val_acc: 0.5143\n",
      "Epoch 11/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3112 - acc: 0.7266 - val_loss: 0.4811 - val_acc: 0.5143\n",
      "Epoch 12/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2915 - acc: 0.7410 - val_loss: 0.4504 - val_acc: 0.6286\n",
      "Epoch 13/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2881 - acc: 0.7410 - val_loss: 0.4511 - val_acc: 0.6286\n",
      "Epoch 14/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2319 - acc: 0.8058 - val_loss: 0.4430 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2448 - acc: 0.7554 - val_loss: 0.4566 - val_acc: 0.5143\n",
      "Epoch 16/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2126 - acc: 0.8129 - val_loss: 0.5010 - val_acc: 0.4857\n",
      "Epoch 17/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2176 - acc: 0.8201 - val_loss: 0.4053 - val_acc: 0.6571\n",
      "Epoch 18/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1855 - acc: 0.8417 - val_loss: 0.4091 - val_acc: 0.6000\n",
      "Epoch 19/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1833 - acc: 0.8417 - val_loss: 0.4209 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1811 - acc: 0.8561 - val_loss: 0.4731 - val_acc: 0.4857\n",
      "Epoch 21/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1812 - acc: 0.8561 - val_loss: 0.4458 - val_acc: 0.5429\n",
      "Epoch 22/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1137 - acc: 0.9281 - val_loss: 0.4014 - val_acc: 0.6571\n",
      "Epoch 23/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1107 - acc: 0.9424 - val_loss: 0.4241 - val_acc: 0.5714\n",
      "Epoch 24/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1271 - acc: 0.9137 - val_loss: 0.3883 - val_acc: 0.6286\n",
      "Epoch 25/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0904 - acc: 0.9424 - val_loss: 0.3825 - val_acc: 0.6857\n",
      "Epoch 26/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0972 - acc: 0.9424 - val_loss: 0.4085 - val_acc: 0.6571\n",
      "Epoch 27/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1206 - acc: 0.9209 - val_loss: 0.4050 - val_acc: 0.6286\n",
      "Epoch 28/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0877 - acc: 0.9424 - val_loss: 0.4042 - val_acc: 0.6286\n",
      "Epoch 29/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0741 - acc: 0.9568 - val_loss: 0.4052 - val_acc: 0.7429\n",
      "Epoch 30/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1023 - acc: 0.9568 - val_loss: 0.4070 - val_acc: 0.7429\n",
      "Epoch 31/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0679 - acc: 0.9856 - val_loss: 0.3920 - val_acc: 0.7143\n",
      "Epoch 32/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0653 - acc: 0.9784 - val_loss: 0.4000 - val_acc: 0.6286\n",
      "Epoch 33/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0498 - acc: 0.9928 - val_loss: 0.3923 - val_acc: 0.6571\n",
      "Epoch 34/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0550 - acc: 0.9856 - val_loss: 0.3773 - val_acc: 0.7143\n",
      "Epoch 35/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0488 - acc: 0.9928 - val_loss: 0.3876 - val_acc: 0.6571\n",
      "Epoch 36/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0474 - acc: 0.9856 - val_loss: 0.3865 - val_acc: 0.6857\n",
      "Epoch 37/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0398 - acc: 0.9928 - val_loss: 0.3945 - val_acc: 0.7143\n",
      "Epoch 38/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0549 - acc: 0.9640 - val_loss: 0.3966 - val_acc: 0.6857\n",
      "Epoch 39/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0461 - acc: 0.9712 - val_loss: 0.3927 - val_acc: 0.6857\n",
      "Epoch 40/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0495 - acc: 0.9856 - val_loss: 0.3866 - val_acc: 0.6857\n",
      "Epoch 41/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0327 - acc: 0.9856 - val_loss: 0.3879 - val_acc: 0.7143\n",
      "Epoch 42/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.3946 - val_acc: 0.7143\n",
      "Epoch 43/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0344 - acc: 1.0000 - val_loss: 0.4064 - val_acc: 0.6286\n",
      "Epoch 44/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0380 - acc: 0.9928 - val_loss: 0.3901 - val_acc: 0.6857\n",
      "Epoch 45/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.4060 - val_acc: 0.6857\n",
      "Epoch 46/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.4330 - val_acc: 0.6571\n",
      "Epoch 47/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0304 - acc: 0.9856 - val_loss: 0.4175 - val_acc: 0.6286\n",
      "Epoch 48/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0252 - acc: 0.9928 - val_loss: 0.3986 - val_acc: 0.6286\n",
      "Epoch 49/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0227 - acc: 0.9856 - val_loss: 0.3843 - val_acc: 0.7429\n",
      "Epoch 50/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.3797 - val_acc: 0.7143\n",
      "Epoch 51/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0282 - acc: 0.9856 - val_loss: 0.3767 - val_acc: 0.7429\n",
      "Epoch 52/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.3781 - val_acc: 0.7143\n",
      "Epoch 53/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0188 - acc: 0.9928 - val_loss: 0.3847 - val_acc: 0.6857\n",
      "Epoch 54/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0213 - acc: 0.9856 - val_loss: 0.3963 - val_acc: 0.6286\n",
      "Epoch 55/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.3842 - val_acc: 0.7429\n",
      "Epoch 56/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0206 - acc: 0.9928 - val_loss: 0.3861 - val_acc: 0.6571\n",
      "Epoch 57/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.3781 - val_acc: 0.6857\n",
      "Epoch 58/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.3790 - val_acc: 0.6571\n",
      "Epoch 59/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.3839 - val_acc: 0.6857\n",
      "Epoch 60/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0226 - acc: 0.9928 - val_loss: 0.3807 - val_acc: 0.7429\n",
      "Epoch 61/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0247 - acc: 0.9856 - val_loss: 0.3793 - val_acc: 0.7143\n",
      "Epoch 62/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0160 - acc: 0.9928 - val_loss: 0.3792 - val_acc: 0.7143\n",
      "Epoch 63/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.3838 - val_acc: 0.6286\n",
      "Epoch 64/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.3799 - val_acc: 0.6286\n",
      "Epoch 65/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0180 - acc: 0.9928 - val_loss: 0.3776 - val_acc: 0.6571\n",
      "Epoch 66/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0190 - acc: 0.9928 - val_loss: 0.3674 - val_acc: 0.6857\n",
      "Epoch 67/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.3783 - val_acc: 0.7143\n",
      "Epoch 68/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0245 - acc: 0.9856 - val_loss: 0.3866 - val_acc: 0.7143\n",
      "Epoch 69/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3822 - val_acc: 0.7143\n",
      "Epoch 70/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.3764 - val_acc: 0.7143\n",
      "Epoch 71/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3790 - val_acc: 0.6571\n",
      "Epoch 72/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.3716 - val_acc: 0.6571\n",
      "Epoch 73/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3705 - val_acc: 0.7143\n",
      "Epoch 74/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3727 - val_acc: 0.7143\n",
      "Epoch 75/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0133 - acc: 0.9928 - val_loss: 0.3785 - val_acc: 0.7143\n",
      "Epoch 76/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0177 - acc: 0.9928 - val_loss: 0.3776 - val_acc: 0.7143\n",
      "Epoch 77/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3797 - val_acc: 0.7143\n",
      "Epoch 78/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3747 - val_acc: 0.7429\n",
      "Epoch 79/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3793 - val_acc: 0.6286\n",
      "Epoch 80/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.3877 - val_acc: 0.6000\n",
      "Epoch 81/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3757 - val_acc: 0.6857\n",
      "Epoch 82/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3766 - val_acc: 0.7429\n",
      "Epoch 83/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.3835 - val_acc: 0.7429\n",
      "Epoch 84/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.3828 - val_acc: 0.7429\n",
      "Epoch 85/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3793 - val_acc: 0.7429\n",
      "Epoch 86/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3726 - val_acc: 0.7143\n",
      "Epoch 87/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0156 - acc: 0.9928 - val_loss: 0.3739 - val_acc: 0.6857\n",
      "Epoch 88/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3877 - val_acc: 0.6286\n",
      "Epoch 89/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0119 - acc: 0.9928 - val_loss: 0.3894 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3727 - val_acc: 0.6571\n",
      "Epoch 91/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.3697 - val_acc: 0.7143\n",
      "Epoch 92/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0134 - acc: 0.9928 - val_loss: 0.3707 - val_acc: 0.6857\n",
      "Epoch 93/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.3723 - val_acc: 0.6857\n",
      "Epoch 94/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.3736 - val_acc: 0.6857\n",
      "Epoch 95/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.3695 - val_acc: 0.6571\n",
      "Epoch 96/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0123 - acc: 0.9928 - val_loss: 0.3704 - val_acc: 0.7143\n",
      "Epoch 97/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3655 - val_acc: 0.7143\n",
      "Epoch 98/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.3598 - val_acc: 0.7143\n",
      "Epoch 99/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3574 - val_acc: 0.7143\n",
      "Epoch 100/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3626 - val_acc: 0.7143\n",
      "Fold 1 accuracy : 71.42857142857143\n",
      "Fold - 2 (139, 128, 128, 64, 1) (139,) (35, 128, 128, 64, 1) (35,)\n",
      "Train on 139 samples, validate on 35 samples\n",
      "Epoch 1/100\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 0.5590 - acc: 0.4388 - val_loss: 0.4991 - val_acc: 0.5143\n",
      "Epoch 2/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4783 - acc: 0.5468 - val_loss: 0.4960 - val_acc: 0.5143\n",
      "Epoch 3/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.5029 - acc: 0.4892 - val_loss: 0.4933 - val_acc: 0.5143\n",
      "Epoch 4/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3969 - acc: 0.6115 - val_loss: 0.4919 - val_acc: 0.5143\n",
      "Epoch 5/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4114 - acc: 0.5971 - val_loss: 0.4901 - val_acc: 0.5143\n",
      "Epoch 6/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4226 - acc: 0.5755 - val_loss: 0.4888 - val_acc: 0.5143\n",
      "Epoch 7/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3901 - acc: 0.6115 - val_loss: 0.4860 - val_acc: 0.5143\n",
      "Epoch 8/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3661 - acc: 0.6547 - val_loss: 0.4840 - val_acc: 0.5143\n",
      "Epoch 9/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3231 - acc: 0.6835 - val_loss: 0.4726 - val_acc: 0.5143\n",
      "Epoch 10/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3407 - acc: 0.7194 - val_loss: 0.4546 - val_acc: 0.5714\n",
      "Epoch 11/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3040 - acc: 0.6978 - val_loss: 0.4533 - val_acc: 0.6000\n",
      "Epoch 12/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2778 - acc: 0.7410 - val_loss: 0.4489 - val_acc: 0.5429\n",
      "Epoch 13/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2482 - acc: 0.7986 - val_loss: 0.4570 - val_acc: 0.5143\n",
      "Epoch 14/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2131 - acc: 0.8129 - val_loss: 0.4326 - val_acc: 0.6571\n",
      "Epoch 15/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2339 - acc: 0.8058 - val_loss: 0.4604 - val_acc: 0.5429\n",
      "Epoch 16/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1964 - acc: 0.8345 - val_loss: 0.4570 - val_acc: 0.4857\n",
      "Epoch 17/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2026 - acc: 0.8345 - val_loss: 0.4352 - val_acc: 0.5429\n",
      "Epoch 18/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1400 - acc: 0.8993 - val_loss: 0.4188 - val_acc: 0.5714\n",
      "Epoch 19/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1885 - acc: 0.8489 - val_loss: 0.4214 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1949 - acc: 0.8561 - val_loss: 0.4213 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1308 - acc: 0.9137 - val_loss: 0.4133 - val_acc: 0.6286\n",
      "Epoch 22/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1419 - acc: 0.9065 - val_loss: 0.4197 - val_acc: 0.6286\n",
      "Epoch 23/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1161 - acc: 0.9137 - val_loss: 0.4315 - val_acc: 0.5714\n",
      "Epoch 24/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1351 - acc: 0.8921 - val_loss: 0.4125 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1055 - acc: 0.9424 - val_loss: 0.4374 - val_acc: 0.5143\n",
      "Epoch 26/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1101 - acc: 0.9424 - val_loss: 0.4186 - val_acc: 0.6286\n",
      "Epoch 27/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0885 - acc: 0.9640 - val_loss: 0.4140 - val_acc: 0.6286\n",
      "Epoch 28/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0960 - acc: 0.9568 - val_loss: 0.4344 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0610 - acc: 0.9640 - val_loss: 0.4259 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0560 - acc: 0.9784 - val_loss: 0.4200 - val_acc: 0.5714\n",
      "Epoch 31/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0603 - acc: 0.9856 - val_loss: 0.4263 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0665 - acc: 0.9712 - val_loss: 0.4294 - val_acc: 0.5429\n",
      "Epoch 33/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0739 - acc: 0.9568 - val_loss: 0.4384 - val_acc: 0.5429\n",
      "Epoch 34/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0599 - acc: 0.9712 - val_loss: 0.4257 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0800 - acc: 0.9496 - val_loss: 0.4314 - val_acc: 0.5143\n",
      "Epoch 36/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0659 - acc: 0.9784 - val_loss: 0.4338 - val_acc: 0.5714\n",
      "Epoch 37/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0442 - acc: 0.9712 - val_loss: 0.4171 - val_acc: 0.6286\n",
      "Epoch 38/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.4120 - val_acc: 0.6286\n",
      "Epoch 39/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0490 - acc: 0.9784 - val_loss: 0.4286 - val_acc: 0.5429\n",
      "Epoch 40/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0590 - acc: 0.9640 - val_loss: 0.4146 - val_acc: 0.6286\n",
      "Epoch 41/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0435 - acc: 0.9784 - val_loss: 0.4108 - val_acc: 0.6286\n",
      "Epoch 42/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0444 - acc: 0.9928 - val_loss: 0.4206 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0367 - acc: 1.0000 - val_loss: 0.4189 - val_acc: 0.5714\n",
      "Epoch 44/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0354 - acc: 0.9856 - val_loss: 0.4156 - val_acc: 0.5714\n",
      "Epoch 45/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0392 - acc: 0.9928 - val_loss: 0.4281 - val_acc: 0.5714\n",
      "Epoch 46/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0414 - acc: 0.9856 - val_loss: 0.4280 - val_acc: 0.5714\n",
      "Epoch 47/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.4236 - val_acc: 0.5714\n",
      "Epoch 48/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0335 - acc: 0.9928 - val_loss: 0.4204 - val_acc: 0.5714\n",
      "Epoch 49/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0275 - acc: 0.9928 - val_loss: 0.4154 - val_acc: 0.5714\n",
      "Epoch 50/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0211 - acc: 0.9928 - val_loss: 0.4087 - val_acc: 0.6000\n",
      "Epoch 51/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0290 - acc: 0.9856 - val_loss: 0.4158 - val_acc: 0.6000\n",
      "Epoch 52/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.4204 - val_acc: 0.5714\n",
      "Epoch 53/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0306 - acc: 0.9856 - val_loss: 0.4214 - val_acc: 0.5714\n",
      "Epoch 54/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0311 - acc: 0.9856 - val_loss: 0.4240 - val_acc: 0.5429\n",
      "Epoch 55/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0280 - acc: 0.9928 - val_loss: 0.4223 - val_acc: 0.5429\n",
      "Epoch 56/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.4218 - val_acc: 0.5429\n",
      "Epoch 57/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.4191 - val_acc: 0.6000\n",
      "Epoch 58/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0233 - acc: 0.9928 - val_loss: 0.4238 - val_acc: 0.6000\n",
      "Epoch 59/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.4222 - val_acc: 0.5714\n",
      "Epoch 60/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.4227 - val_acc: 0.5714\n",
      "Epoch 61/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4233 - val_acc: 0.5714\n",
      "Epoch 62/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.4260 - val_acc: 0.5714\n",
      "Epoch 63/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0153 - acc: 0.9928 - val_loss: 0.4351 - val_acc: 0.5429\n",
      "Epoch 64/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0189 - acc: 0.9928 - val_loss: 0.4334 - val_acc: 0.6000\n",
      "Epoch 65/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.4230 - val_acc: 0.5429\n",
      "Epoch 66/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4166 - val_acc: 0.5714\n",
      "Epoch 67/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0173 - acc: 0.9928 - val_loss: 0.4265 - val_acc: 0.5714\n",
      "Epoch 68/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4370 - val_acc: 0.5429\n",
      "Epoch 69/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0141 - acc: 0.9928 - val_loss: 0.4421 - val_acc: 0.5429\n",
      "Epoch 70/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.4324 - val_acc: 0.5429\n",
      "Epoch 71/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4201 - val_acc: 0.5714\n",
      "Epoch 72/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0179 - acc: 0.9928 - val_loss: 0.4192 - val_acc: 0.6000\n",
      "Epoch 73/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.4297 - val_acc: 0.6000\n",
      "Epoch 74/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.4418 - val_acc: 0.5429\n",
      "Epoch 75/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4354 - val_acc: 0.6000\n",
      "Epoch 76/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.4254 - val_acc: 0.5429\n",
      "Epoch 77/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4254 - val_acc: 0.5429\n",
      "Epoch 78/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4238 - val_acc: 0.5714\n",
      "Epoch 79/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.4199 - val_acc: 0.6000\n",
      "Epoch 80/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4250 - val_acc: 0.5714\n",
      "Epoch 81/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0100 - acc: 0.9928 - val_loss: 0.4238 - val_acc: 0.5714\n",
      "Epoch 82/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4238 - val_acc: 0.5429\n",
      "Epoch 83/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4197 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4199 - val_acc: 0.5714\n",
      "Epoch 85/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4214 - val_acc: 0.5714\n",
      "Epoch 86/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4209 - val_acc: 0.5714\n",
      "Epoch 87/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4218 - val_acc: 0.5714\n",
      "Epoch 88/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4258 - val_acc: 0.5714\n",
      "Epoch 89/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4223 - val_acc: 0.5714\n",
      "Epoch 90/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4182 - val_acc: 0.5429\n",
      "Epoch 91/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.4139 - val_acc: 0.5143\n",
      "Epoch 92/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4138 - val_acc: 0.5429\n",
      "Epoch 93/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.4155 - val_acc: 0.5429\n",
      "Epoch 94/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4193 - val_acc: 0.5429\n",
      "Epoch 95/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0169 - acc: 0.9928 - val_loss: 0.4237 - val_acc: 0.5429\n",
      "Epoch 96/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4209 - val_acc: 0.5714\n",
      "Epoch 97/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4234 - val_acc: 0.5714\n",
      "Epoch 98/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.4296 - val_acc: 0.5429\n",
      "Epoch 99/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4354 - val_acc: 0.5143\n",
      "Epoch 100/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4281 - val_acc: 0.5429\n",
      "Fold 2 accuracy : 54.285714285714285\n",
      "Fold - 3 (139, 128, 128, 64, 1) (139,) (35, 128, 128, 64, 1) (35,)\n",
      "Train on 139 samples, validate on 35 samples\n",
      "Epoch 1/100\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 0.5001 - acc: 0.5108 - val_loss: 0.4934 - val_acc: 0.5143\n",
      "Epoch 2/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4528 - acc: 0.5540 - val_loss: 0.4896 - val_acc: 0.5143\n",
      "Epoch 3/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4680 - acc: 0.5324 - val_loss: 0.4880 - val_acc: 0.5143\n",
      "Epoch 4/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.4160 - acc: 0.5971 - val_loss: 0.4870 - val_acc: 0.5143\n",
      "Epoch 5/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3724 - acc: 0.6763 - val_loss: 0.4863 - val_acc: 0.5143\n",
      "Epoch 6/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3885 - acc: 0.5971 - val_loss: 0.4858 - val_acc: 0.5143\n",
      "Epoch 7/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3955 - acc: 0.6259 - val_loss: 0.4856 - val_acc: 0.5143\n",
      "Epoch 8/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3260 - acc: 0.6763 - val_loss: 0.4858 - val_acc: 0.5143\n",
      "Epoch 9/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3276 - acc: 0.6978 - val_loss: 0.4847 - val_acc: 0.5143\n",
      "Epoch 10/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3300 - acc: 0.7194 - val_loss: 0.4655 - val_acc: 0.5143\n",
      "Epoch 11/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3014 - acc: 0.7266 - val_loss: 0.4529 - val_acc: 0.5143\n",
      "Epoch 12/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.3075 - acc: 0.7050 - val_loss: 0.4239 - val_acc: 0.6571\n",
      "Epoch 13/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2555 - acc: 0.7698 - val_loss: 0.4152 - val_acc: 0.5714\n",
      "Epoch 14/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2071 - acc: 0.8273 - val_loss: 0.4366 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2533 - acc: 0.7698 - val_loss: 0.4326 - val_acc: 0.6000\n",
      "Epoch 16/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.2376 - acc: 0.7986 - val_loss: 0.4313 - val_acc: 0.6000\n",
      "Epoch 17/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1960 - acc: 0.8201 - val_loss: 0.4436 - val_acc: 0.6000\n",
      "Epoch 18/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1910 - acc: 0.8561 - val_loss: 0.4480 - val_acc: 0.5429\n",
      "Epoch 19/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1369 - acc: 0.9137 - val_loss: 0.4223 - val_acc: 0.5429\n",
      "Epoch 20/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1520 - acc: 0.9065 - val_loss: 0.4237 - val_acc: 0.6286\n",
      "Epoch 21/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1266 - acc: 0.9424 - val_loss: 0.4309 - val_acc: 0.5429\n",
      "Epoch 22/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1124 - acc: 0.9209 - val_loss: 0.4097 - val_acc: 0.6571\n",
      "Epoch 23/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0974 - acc: 0.9496 - val_loss: 0.4215 - val_acc: 0.6000\n",
      "Epoch 24/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0870 - acc: 0.9640 - val_loss: 0.4083 - val_acc: 0.6571\n",
      "Epoch 25/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0900 - acc: 0.9568 - val_loss: 0.4050 - val_acc: 0.6286\n",
      "Epoch 26/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.1041 - acc: 0.9353 - val_loss: 0.4197 - val_acc: 0.6286\n",
      "Epoch 27/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0798 - acc: 0.9496 - val_loss: 0.4253 - val_acc: 0.6286\n",
      "Epoch 28/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0703 - acc: 0.9640 - val_loss: 0.4268 - val_acc: 0.6286\n",
      "Epoch 29/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0644 - acc: 0.9784 - val_loss: 0.4203 - val_acc: 0.6286\n",
      "Epoch 30/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.4418 - val_acc: 0.4857\n",
      "Epoch 31/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0564 - acc: 0.9640 - val_loss: 0.4315 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0465 - acc: 0.9928 - val_loss: 0.4228 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0508 - acc: 0.9712 - val_loss: 0.4201 - val_acc: 0.6286\n",
      "Epoch 34/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0554 - acc: 0.9784 - val_loss: 0.4266 - val_acc: 0.5714\n",
      "Epoch 35/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0374 - acc: 0.9784 - val_loss: 0.4272 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0351 - acc: 0.9928 - val_loss: 0.4179 - val_acc: 0.6000\n",
      "Epoch 37/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.4274 - val_acc: 0.6000\n",
      "Epoch 38/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.4300 - val_acc: 0.6000\n",
      "Epoch 39/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.4258 - val_acc: 0.6000\n",
      "Epoch 40/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0462 - acc: 0.9856 - val_loss: 0.4207 - val_acc: 0.6286\n",
      "Epoch 41/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0310 - acc: 0.9928 - val_loss: 0.4214 - val_acc: 0.6000\n",
      "Epoch 42/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.4234 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0256 - acc: 0.9928 - val_loss: 0.4131 - val_acc: 0.6000\n",
      "Epoch 44/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0392 - acc: 0.9928 - val_loss: 0.4099 - val_acc: 0.6000\n",
      "Epoch 45/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0221 - acc: 0.9928 - val_loss: 0.4256 - val_acc: 0.6000\n",
      "Epoch 46/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0210 - acc: 0.9928 - val_loss: 0.4309 - val_acc: 0.6000\n",
      "Epoch 47/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0271 - acc: 0.9928 - val_loss: 0.4245 - val_acc: 0.6286\n",
      "Epoch 48/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.4188 - val_acc: 0.5714\n",
      "Epoch 49/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0236 - acc: 0.9856 - val_loss: 0.4224 - val_acc: 0.5714\n",
      "Epoch 50/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.4239 - val_acc: 0.6000\n",
      "Epoch 51/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0210 - acc: 0.9928 - val_loss: 0.4311 - val_acc: 0.6000\n",
      "Epoch 52/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.4299 - val_acc: 0.5714\n",
      "Epoch 53/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.4238 - val_acc: 0.5714\n",
      "Epoch 54/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0244 - acc: 0.9928 - val_loss: 0.4234 - val_acc: 0.6000\n",
      "Epoch 55/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0178 - acc: 0.9928 - val_loss: 0.4336 - val_acc: 0.6000\n",
      "Epoch 56/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0197 - acc: 0.9928 - val_loss: 0.4362 - val_acc: 0.6000\n",
      "Epoch 57/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.4302 - val_acc: 0.6000\n",
      "Epoch 58/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0158 - acc: 0.9928 - val_loss: 0.4110 - val_acc: 0.6286\n",
      "Epoch 59/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0204 - acc: 0.9928 - val_loss: 0.4096 - val_acc: 0.6286\n",
      "Epoch 60/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.4108 - val_acc: 0.6000\n",
      "Epoch 61/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0161 - acc: 0.9928 - val_loss: 0.4205 - val_acc: 0.5714\n",
      "Epoch 62/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4263 - val_acc: 0.5714\n",
      "Epoch 63/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.4216 - val_acc: 0.6286\n",
      "Epoch 64/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.4202 - val_acc: 0.6000\n",
      "Epoch 65/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.4222 - val_acc: 0.5714\n",
      "Epoch 66/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.4383 - val_acc: 0.5429\n",
      "Epoch 67/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4333 - val_acc: 0.5143\n",
      "Epoch 68/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4238 - val_acc: 0.5714\n",
      "Epoch 69/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0129 - acc: 0.9928 - val_loss: 0.4181 - val_acc: 0.5714\n",
      "Epoch 70/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0146 - acc: 0.9928 - val_loss: 0.4166 - val_acc: 0.6000\n",
      "Epoch 71/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.4275 - val_acc: 0.5429\n",
      "Epoch 72/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4343 - val_acc: 0.5429\n",
      "Epoch 73/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0151 - acc: 0.9928 - val_loss: 0.4318 - val_acc: 0.5429\n",
      "Epoch 74/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4263 - val_acc: 0.6000\n",
      "Epoch 75/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4234 - val_acc: 0.5714\n",
      "Epoch 76/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.4206 - val_acc: 0.6000\n",
      "Epoch 77/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.4230 - val_acc: 0.6000\n",
      "Epoch 78/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0129 - acc: 0.9928 - val_loss: 0.4198 - val_acc: 0.6000\n",
      "Epoch 79/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0140 - acc: 0.9928 - val_loss: 0.4180 - val_acc: 0.6000\n",
      "Epoch 80/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.4284 - val_acc: 0.5714\n",
      "Epoch 81/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4248 - val_acc: 0.5714\n",
      "Epoch 82/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.5714\n",
      "Epoch 83/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4107 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.6286\n",
      "Epoch 85/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4192 - val_acc: 0.6286\n",
      "Epoch 86/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4162 - val_acc: 0.5714\n",
      "Epoch 87/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4197 - val_acc: 0.6286\n",
      "Epoch 88/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4256 - val_acc: 0.5714\n",
      "Epoch 89/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4224 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4170 - val_acc: 0.5429\n",
      "Epoch 91/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4228 - val_acc: 0.5714\n",
      "Epoch 92/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4248 - val_acc: 0.5714\n",
      "Epoch 93/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4265 - val_acc: 0.5714\n",
      "Epoch 94/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.4252 - val_acc: 0.5714\n",
      "Epoch 95/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4315 - val_acc: 0.6000\n",
      "Epoch 96/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4342 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4260 - val_acc: 0.5714\n",
      "Epoch 98/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4185 - val_acc: 0.5714\n",
      "Epoch 99/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4137 - val_acc: 0.6000\n",
      "Epoch 100/100\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4128 - val_acc: 0.6000\n",
      "Fold 3 accuracy : 60.0\n",
      "Fold - 4 (140, 128, 128, 64, 1) (140,) (34, 128, 128, 64, 1) (34,)\n",
      "Train on 140 samples, validate on 34 samples\n",
      "Epoch 1/100\n",
      "140/140 [==============================] - 6s 46ms/step - loss: 0.4664 - acc: 0.5357 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.4753 - acc: 0.4929 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.4649 - acc: 0.5571 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.4590 - acc: 0.5714 - val_loss: 0.5006 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.4743 - acc: 0.5000 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.3903 - acc: 0.6286 - val_loss: 0.5023 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.4372 - acc: 0.6071 - val_loss: 0.5030 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.4046 - acc: 0.6143 - val_loss: 0.5074 - val_acc: 0.4412\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.3493 - acc: 0.6786 - val_loss: 0.4969 - val_acc: 0.6176\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.3609 - acc: 0.6857 - val_loss: 0.4930 - val_acc: 0.5882\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.3495 - acc: 0.6500 - val_loss: 0.4718 - val_acc: 0.5588\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.3166 - acc: 0.6714 - val_loss: 0.4465 - val_acc: 0.5294\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.2569 - acc: 0.7714 - val_loss: 0.4242 - val_acc: 0.6176\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.2625 - acc: 0.7857 - val_loss: 0.4129 - val_acc: 0.6176\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.2485 - acc: 0.7857 - val_loss: 0.3902 - val_acc: 0.6765\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.2421 - acc: 0.8071 - val_loss: 0.4046 - val_acc: 0.6471\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.2577 - acc: 0.7786 - val_loss: 0.4486 - val_acc: 0.5588\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.2365 - acc: 0.8071 - val_loss: 0.4459 - val_acc: 0.5588\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.2146 - acc: 0.8214 - val_loss: 0.4495 - val_acc: 0.5588\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.2035 - acc: 0.8357 - val_loss: 0.4062 - val_acc: 0.6176\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1667 - acc: 0.8500 - val_loss: 0.4158 - val_acc: 0.6176\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1830 - acc: 0.8429 - val_loss: 0.4177 - val_acc: 0.6176\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1554 - acc: 0.8857 - val_loss: 0.4213 - val_acc: 0.6471\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1394 - acc: 0.9071 - val_loss: 0.3966 - val_acc: 0.6471\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1401 - acc: 0.9071 - val_loss: 0.4302 - val_acc: 0.5588\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1301 - acc: 0.9000 - val_loss: 0.4601 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1652 - acc: 0.8929 - val_loss: 0.4150 - val_acc: 0.5882\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1150 - acc: 0.9143 - val_loss: 0.4228 - val_acc: 0.6176\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1030 - acc: 0.9429 - val_loss: 0.4208 - val_acc: 0.5882\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0724 - acc: 0.9714 - val_loss: 0.4447 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.1114 - acc: 0.9286 - val_loss: 0.4354 - val_acc: 0.5882\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0882 - acc: 0.9429 - val_loss: 0.3920 - val_acc: 0.6471\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0881 - acc: 0.9500 - val_loss: 0.3959 - val_acc: 0.6471\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0673 - acc: 0.9786 - val_loss: 0.4306 - val_acc: 0.6176\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0770 - acc: 0.9571 - val_loss: 0.4284 - val_acc: 0.6471\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0634 - acc: 0.9571 - val_loss: 0.4110 - val_acc: 0.6176\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0588 - acc: 0.9643 - val_loss: 0.4116 - val_acc: 0.6176\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0693 - acc: 0.9571 - val_loss: 0.4023 - val_acc: 0.6176\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0471 - acc: 0.9857 - val_loss: 0.4126 - val_acc: 0.6176\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0476 - acc: 1.0000 - val_loss: 0.4122 - val_acc: 0.6471\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0566 - acc: 0.9714 - val_loss: 0.3999 - val_acc: 0.6176\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0615 - acc: 0.9786 - val_loss: 0.4228 - val_acc: 0.6176\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0487 - acc: 0.9786 - val_loss: 0.4326 - val_acc: 0.6176\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.4379 - val_acc: 0.5294\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0423 - acc: 0.9929 - val_loss: 0.4132 - val_acc: 0.5882\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0452 - acc: 0.9929 - val_loss: 0.4229 - val_acc: 0.5882\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0531 - acc: 0.9714 - val_loss: 0.4264 - val_acc: 0.5882\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0445 - acc: 0.9929 - val_loss: 0.4240 - val_acc: 0.6176\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.4216 - val_acc: 0.6176\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0294 - acc: 0.9929 - val_loss: 0.4257 - val_acc: 0.5588\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0352 - acc: 0.9929 - val_loss: 0.4067 - val_acc: 0.6471\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0311 - acc: 0.9929 - val_loss: 0.4159 - val_acc: 0.6471\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0286 - acc: 0.9929 - val_loss: 0.4297 - val_acc: 0.6176\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0328 - acc: 0.9929 - val_loss: 0.4366 - val_acc: 0.5882\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.4377 - val_acc: 0.5882\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.4196 - val_acc: 0.6176\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0381 - acc: 0.9786 - val_loss: 0.3988 - val_acc: 0.6471\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.4016 - val_acc: 0.6176\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.4207 - val_acc: 0.5588\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.4255 - val_acc: 0.6176\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.4266 - val_acc: 0.6176\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.4267 - val_acc: 0.6176\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.4238 - val_acc: 0.6176\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.4309 - val_acc: 0.5882\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.4285 - val_acc: 0.6176\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.4136 - val_acc: 0.6176\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.4086 - val_acc: 0.6176\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4120 - val_acc: 0.6176\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4187 - val_acc: 0.6176\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.4166 - val_acc: 0.6176\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4197 - val_acc: 0.6176\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0180 - acc: 0.9929 - val_loss: 0.4215 - val_acc: 0.6176\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.4145 - val_acc: 0.6176\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.4148 - val_acc: 0.6176\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.4207 - val_acc: 0.5882\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.4106 - val_acc: 0.6176\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4194 - val_acc: 0.6176\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.4171 - val_acc: 0.6471\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4273 - val_acc: 0.5882\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4292 - val_acc: 0.6176\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.4316 - val_acc: 0.5588\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.4231 - val_acc: 0.6176\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4157 - val_acc: 0.6176\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0138 - acc: 0.9929 - val_loss: 0.4144 - val_acc: 0.5882\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4229 - val_acc: 0.6176\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4240 - val_acc: 0.6176\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.4226 - val_acc: 0.6471\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0181 - acc: 0.9929 - val_loss: 0.4174 - val_acc: 0.6176\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.4100 - val_acc: 0.6176\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4153 - val_acc: 0.6176\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4153 - val_acc: 0.6176\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4141 - val_acc: 0.6176\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4167 - val_acc: 0.5882\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0185 - acc: 0.9929 - val_loss: 0.4185 - val_acc: 0.5882\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4181 - val_acc: 0.6176\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4164 - val_acc: 0.6176\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0143 - acc: 0.9929 - val_loss: 0.4118 - val_acc: 0.6176\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4084 - val_acc: 0.5882\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4112 - val_acc: 0.6176\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 6s 42ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4170 - val_acc: 0.6176\n",
      "Fold 4 accuracy : 61.76470588235294\n",
      "1580256455.1411881 1580257044.0788336\n",
      "--- Time taken to train : 9.0 minutes ---\n",
      "--- Time taken to train : 0.0 hours ---\n"
     ]
    }
   ],
   "source": [
    "# kfold cross validation\n",
    "# https://www.kaggle.com/sharifamit19/data-augmentation-cross-validation-ensemble\n",
    "\n",
    "# Cross validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# define 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "print(kfold)\n",
    "\n",
    "data = X_train\n",
    "labels = np.array([np.argmax(x) for x in y_train])\n",
    "\n",
    "print(data.shape, labels.shape)\n",
    "\n",
    "# Store scores here\n",
    "cross_val_scores = []\n",
    "\n",
    "\n",
    "# Calculate the starting time    \n",
    "start_time = time.time()\n",
    "\n",
    "# Run folds\n",
    "for i, (train, test) in enumerate(kfold.split(data, labels)):\n",
    "    \n",
    "    print(\"Fold - {}\".format(i), data[train].shape, labels[train].shape, data[test].shape, labels[test].shape)\n",
    "    \n",
    "    # Clearing the NN.\n",
    "    #K.clear_session()\n",
    "    model = None \n",
    "    \n",
    "    # Calculate the starting time    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create the model\n",
    "    model = awesome_3D_network()\n",
    "    \n",
    "    # One hot :convert class vectors to binary class matrices\n",
    "    y_train_cv = keras.utils.to_categorical(labels[train], 2)\n",
    "    y_val_cv = keras.utils.to_categorical(labels[test], 2)\n",
    "    \n",
    "    # Set callbacks\n",
    "    cb = None #[csv_logger, early_stopping, reduce_lr, checkpointer]\n",
    "    cw = None #class_weights\n",
    "\n",
    "    # Train\n",
    "    h=model.fit(x=data[train],     \n",
    "                y=y_train_cv,\n",
    "                validation_data=(data[test], y_val_cv), \n",
    "                batch_size=2, \n",
    "                epochs=100, \n",
    "                verbose=1,\n",
    "                class_weight = cw,\n",
    "                callbacks=cb,\n",
    "                shuffle=False,\n",
    "                )\n",
    "\n",
    "    # Evaluate\n",
    "\n",
    "    #score = model.evaluate(data[test], y_val_cv, verbose=0)\n",
    "    #loss, acc = score[0], score[1]\n",
    "\n",
    "    # Validation predictions stored here\n",
    "    y_pred_cv = []\n",
    "\n",
    "    # Iterate over images in validation\n",
    "    for img in data[test]:\n",
    "        img = np.expand_dims(img, axis=0)  # rank 4 tensor for prediction\n",
    "        y = model.predict(img)\n",
    "        y_pred_cv.append(y[:][0])\n",
    "\n",
    "    # Numpy\n",
    "    y_pred_cv = np.array(y_pred_cv)\n",
    "    \n",
    "    # Convert ground truth to column values\n",
    "    y_val_cv_flat = np.argmax(y_val_cv, axis=1)\n",
    "    # Get labels from predictions\n",
    "    y_pred_cv_flat = np.array([np.argmax(pred) for pred in y_pred_cv]) # y_pred[1] -> probability for class 1 \n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_val_cv_flat, y_pred_cv_flat) * 100\n",
    "    print(\"Fold {} accuracy :\".format(i), acc)\n",
    "\n",
    "    cross_val_scores.append(acc)\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(start_time, end_time)\n",
    "print(\"--- Time taken to train : %s minutes ---\" % ((end_time - start_time)//60))\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpGKr9eu-e0M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.64% (+/- 5.73%)\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cross_val_scores), np.std(cross_val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vYDs1AhB4u8"
   },
   "outputs": [],
   "source": [
    "#SIZ: 62.03% (+/- 4.15%) #62.64% (+/- 5.73%)\n",
    "#SSS: 61.48% (+/- 2.50%)\n",
    "#ESS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPox7VRvB4zd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7KmWAqmtp-N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncb = None #[csv_logger, early_stopping, reduce_lr, checkpointer]\\ncw = None #class_weights\\n\\n# Calculate the starting time    \\nstart_time = time.time()\\n\\n# One hot :convert class vectors to binary class matrices\\ny_train_cv = keras.utils.to_categorical(y_train, 2)\\ny_val_cv = keras.utils.to_categorical(y_val, 2)\\n\\n# Train\\nh=model.fit(x=X_train,     \\n            y=y_train,\\n            validation_data=(X_val, y_val), \\n            batch_size=2, \\n            epochs=100, \\n            verbose=1,\\n            class_weight = cw,\\n            callbacks=cb,\\n            shuffle=False,\\n            )\\n\\nend_time = time.time()\\nprint(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cb = None #[csv_logger, early_stopping, reduce_lr, checkpointer]\n",
    "cw = None #class_weights\n",
    "\n",
    "# Calculate the starting time    \n",
    "start_time = time.time()\n",
    "\n",
    "# One hot :convert class vectors to binary class matrices\n",
    "y_train_cv = keras.utils.to_categorical(y_train, 2)\n",
    "y_val_cv = keras.utils.to_categorical(y_val, 2)\n",
    "\n",
    "# Train\n",
    "h=model.fit(x=X_train,     \n",
    "            y=y_train,\n",
    "            validation_data=(X_val, y_val), \n",
    "            batch_size=2, \n",
    "            epochs=100, \n",
    "            verbose=1,\n",
    "            class_weight = cw,\n",
    "            callbacks=cb,\n",
    "            shuffle=False,\n",
    "            )\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bC3nKRDxUMm8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training and logging!\n"
     ]
    }
   ],
   "source": [
    "# Plot and save accuravy loss graphs together\n",
    "def plot_loss_accu_all(history):\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    epochs = range(len(loss))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'r')\n",
    "    plt.plot(epochs, val_acc, 'b')\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.plot(epochs, val_loss, 'y')\n",
    "    plt.title('Accuracy/Loss graph')\n",
    "    \n",
    "    plt.ylabel('Performance Measure')\n",
    "    plt.xlabel('Epochs')\n",
    "    \n",
    "    plt.legend(['trainacc', 'valacc', 'trainloss', 'valloss'], loc='lower right', fontsize=10)\n",
    "    plt.grid(True)\n",
    "    plt.savefig('{}/{}.png'.format(log_path+\"/\"+experiment_name, \"trainval_acc_loss\"), dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot and save accuravy loss graphs individually\n",
    "def plot_loss_accu(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.plot(epochs, val_loss, 'y')\n",
    "    #plt.title('Training and validation loss')\n",
    "    plt.ylabel('Loss %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('{}/{}_loss.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    #plt.savefig('{}/{}_loss.pdf'.format(output_path, EXP_NAME), dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    loss = history.history['acc']\n",
    "    val_loss = history.history['val_acc']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.plot(epochs, val_loss, 'b')\n",
    "    #plt.title('Training and validation accuracy')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('{}/{}_acc.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    #plt.savefig('{}/{}_acc.pdf'.format(output_path, EXP_NAME), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_accu_all(model.history)\n",
    "print(\"Done training and logging!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17qsdZzX3qcB"
   },
   "outputs": [],
   "source": [
    "model.save(\"{}/{}.h5\".format(log_path+\"/\"+experiment_name, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGYJW-hwTUZw"
   },
   "outputs": [],
   "source": [
    "#model = None\n",
    "#model = load_model(\"{}/best_model.h5\".format(model_path))\n",
    "\n",
    "#score = model.evaluate(X_test, y_test, verbose=1)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YECSNf0vtTj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference on hold out test set\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for img in X_test:\n",
    "  img = np.expand_dims(img, axis=0)  # rank 4 tensor for prediction\n",
    "  y = model.predict(img)\n",
    "  y_pred.append(y[:][0])\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wc9BbiRXTUdL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After flattening ground truth:  (44,)\n",
      "Binarize probability values:  (44,)\n",
      "Accuracy : 61.36363636363637\n"
     ]
    }
   ],
   "source": [
    "# Convert ground truth to column values\n",
    "y_test_flat = np.argmax(y_test, axis=1)\n",
    "print(\"After flattening ground truth: \", y_test_flat.shape)\n",
    "\n",
    "# Get labels from predictions\n",
    "y_pred_flat = np.array([np.argmax(pred) for pred in y_pred]) # y_pred[1] -> probability for class 1 \n",
    "print(\"Binarize probability values: \", y_pred_flat.shape)\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "\n",
    "acc = accuracy_score(y_test_flat, y_pred_flat) * 100\n",
    "print(\"Accuracy :\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIZ: 63.63\n",
    "# SSS: 59.09\n",
    "# ESS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64nwLFXbw2Vm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 12]\n",
      " [ 5 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        24\n",
      "           1       0.56      0.75      0.64        20\n",
      "\n",
      "    accuracy                           0.61        44\n",
      "   macro avg       0.63      0.62      0.61        44\n",
      "weighted avg       0.64      0.61      0.61        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test_flat, y_pred_flat) \n",
    "print(confusion_mtx)\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test_flat, y_pred_flat, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSIZ:\\n[[12 12]\\n [ 4 16]]\\n              precision    recall  f1-score   support\\n\\n           0       0.75      0.50      0.60        24\\n           1       0.57      0.80      0.67        20\\n\\n    accuracy                           0.64        44\\n   macro avg       0.66      0.65      0.63        44\\nweighted avg       0.67      0.64      0.63        44\\n\\nSSS:\\n\\n[[14 10]\\n [ 8 12]]\\n              precision    recall  f1-score   support\\n\\n           0       0.64      0.58      0.61        24\\n           1       0.55      0.60      0.57        20\\n\\n    accuracy                           0.59        44\\n   macro avg       0.59      0.59      0.59        44\\nweighted avg       0.60      0.59      0.59        44\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "SIZ:\n",
    "[[12 12]\n",
    " [ 4 16]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.75      0.50      0.60        24\n",
    "           1       0.57      0.80      0.67        20\n",
    "\n",
    "    accuracy                           0.64        44\n",
    "   macro avg       0.66      0.65      0.63        44\n",
    "weighted avg       0.67      0.64      0.63        44\n",
    "\n",
    "SSS:\n",
    "\n",
    "[[14 10]\n",
    " [ 8 12]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.64      0.58      0.61        24\n",
    "           1       0.55      0.60      0.57        20\n",
    "\n",
    "    accuracy                           0.59        44\n",
    "   macro avg       0.59      0.59      0.59        44\n",
    "weighted avg       0.60      0.59      0.59        44\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IEPVB-Qqw2Pe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve :  65.83333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Area under ROC curve : ', roc_auc_score(y_test, y_pred) *100 )\n",
    "\n",
    "# sss 64.99\n",
    "# ess \n",
    "# siz 64.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Hh61ucpx6_c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve for positive class: 0.6583333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "cls = 1 # class name\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#print(roc_auc)\n",
    "print(\"Area under the ROC curve for positive class:\", roc_auc[1])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2 # line width\n",
    "plt.plot(fpr[cls], tpr[cls], color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[cls])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('{}/{}.png'.format(log_path+\"/\"+experiment_name, \"roc\"), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibMnW_4kbhpy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, 0.6583333333333333)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helpers\n",
    "import pickle \n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open('{}'.format(log_path+\"/\") + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('{}'.format(log_path+\"/\") + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "#https://github.com/hasibzunair/MelaNet/blob/master/isic2016_scripts/EDA.ipynb\n",
    "\n",
    "# Save AUCROC for plotting\n",
    "ascore = {}\n",
    "ascore[\"fpr\"] = fpr[cls]\n",
    "ascore[\"tpr\"] = tpr[cls]\n",
    "ascore[\"roc_auc\"] = roc_auc[cls]\n",
    "save_obj(ascore, experiment_name)\n",
    "\n",
    "type(fpr[cls]), roc_auc[cls] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TL4iR6rdVox0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ut7rFRxVor8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCt7UgGMVoqE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crSuFNoYVonr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqN510l6TUgK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qsBAJmom31Ep"
   },
   "source": [
    "### Inference on ImageCLEF test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Syi4HYH73qfX"
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "model = load_model(\"{}/best_model.h5\".format(model_path))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F60ZqaHO3qnP"
   },
   "outputs": [],
   "source": [
    "x_test = expand_dims(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlYy17EB3qtG"
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in x_test:\n",
    "    i = np.expand_dims(i, axis=0)\n",
    "    y_pred = model.predict(i)\n",
    "    res.append(y_pred)\n",
    "    #print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2uoQDJK3qq9"
   },
   "outputs": [],
   "source": [
    "res = np.array(res)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWtc_No1iI7p"
   },
   "outputs": [],
   "source": [
    "res[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95h2C3JlidGr"
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcoXaust3qkz"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "dt = pd.read_csv('{}/TestSet_metaData.csv'.format(dataset_path))\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPBhkjsM3qiy"
   },
   "outputs": [],
   "source": [
    "patient_names = dt['Filename'].values\n",
    "len(patient_names)\n",
    "\n",
    "names = []\n",
    "\n",
    "for name in patient_names:\n",
    "    names.append(name[:-7])\n",
    "\n",
    "names[:5]\n",
    "\n",
    "probab = []\n",
    "\n",
    "for p in res:\n",
    "    # probability of HIGH severity as required to make submission\n",
    "    probab.append(p[0][1])\n",
    "    \n",
    "probab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oyQ2uMD3qY-"
   },
   "outputs": [],
   "source": [
    "for n, p in zip(names, probab):\n",
    "    print(n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qE_cR4n4tqMn"
   },
   "outputs": [],
   "source": [
    "with open('{}/submission.txt'.format(dataset_path), 'w') as f:\n",
    "    for n, p in zip(names, probab):\n",
    "        print(n,\",\", p)\n",
    "        f.write(str(n))\n",
    "        f.write(\",\")\n",
    "        f.write(str(p))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMDeNXJx1TxkuBCBZX5hqeg",
   "collapsed_sections": [],
   "name": "train_clef19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
